{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/30 13:12:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession, types\n",
    "import pyspark.sql.functions as F\n",
    "from  pyspark.sql.functions import col\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.config(\"spark.sql.debug.maxToStringFields\", 100)\n",
    "    .appName(\"reviews\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# data_filepath = \"../data/cleaned_steam_reviews/game_id={70,240,420,620}\"\n",
    "data_filepath = \"../data/cleaned_steam_reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "steam_reviews = spark.read.parquet(data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Doing the heavy lifting in Spark. We could leverage the `histogram` function from the RDD api\n",
    "# select author_playtime_forever where it is not null\n",
    "# and convert playtime from minutes to hours and cast to int\n",
    "\n",
    "playtime = steam_reviews.select('author_playtime_forever').where(col('author_playtime_forever').isNotNull()) \\\n",
    "                .withColumn('author_playtime_forever', col('author_playtime_forever') / 60)\n",
    "\n",
    "# ignore all values that's larger than 100000\n",
    "playtime = playtime.where(col('author_playtime_forever') < 300)\n",
    "\n",
    "# get average of playtiime\n",
    "avg_playtime = playtime.agg(F.avg('author_playtime_forever')).collect()[0][0]\n",
    "# if playtime is larger than average, then set it to average * 2\n",
    "# playtime = playtime.withColumn('author_playtime_forever', F.when(col('author_playtime_forever') > avg_playtime, avg_playtime * 2).otherwise(col('author_playtime_forever')))\n",
    "\n",
    "\n",
    "\n",
    "playtime_hist = playtime.rdd.flatMap(lambda x: x).histogram(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.92663354270596\n"
     ]
    }
   ],
   "source": [
    "print(avg_playtime * 2)\n",
    "print(len(playtime_hist))\n",
    "# deep copy tuple\n",
    "import copy\n",
    "playtime_hist_data = copy.deepcopy(playtime_hist)\n",
    "\n",
    "for i in range(len(playtime_hist_data[0])):\n",
    "    playtime_hist_data[0][i] = int(round(playtime_hist_data[0][i], 0)) * 2\n",
    "\n",
    "histo_data = list(zip(*playtime_hist_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set title\n",
    "pd.DataFrame(\n",
    "    histo_data, \n",
    "    columns=['hours', 'frequency']\n",
    ").set_index(\n",
    "    'hours'\n",
    ").plot(kind='bar').title.set_text('Histogram of Playtime (hours)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Doing the heavy lifting in Spark. We could leverage the `histogram` function from the RDD api\n",
    "# select author_playtime_forever where it is not null\n",
    "# and convert playtime from minutes to hours and cast to int\n",
    "\n",
    "num_of_games = steam_reviews.select('author_num_games_owned').where(col('author_num_games_owned').isNotNull())\n",
    "\n",
    "# ignore all values that's larger than 100000\n",
    "num_of_games = num_of_games.where(col('author_num_games_owned') < 600)\n",
    "\n",
    "# get average of playtiime\n",
    "avg_num_of_games = num_of_games.agg(F.avg('author_num_games_owned')).collect()[0][0]\n",
    "# if playtime is larger than average, then set it to average * 2\n",
    "# playtime = playtime.withColumn('author_playtime_forever', F.when(col('author_playtime_forever') > avg_playtime, avg_playtime * 2).otherwise(col('author_playtime_forever')))\n",
    "\n",
    "\n",
    "\n",
    "num_of_games_hist = num_of_games.rdd.flatMap(lambda x: x).histogram(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.46972746520878\n"
     ]
    }
   ],
   "source": [
    "print(avg_num_of_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.46972746520878\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(avg_num_of_games)\n",
    "print(len(num_of_games_hist))\n",
    "# deep copy tuple\n",
    "import copy\n",
    "num_of_games_hist_data = copy.deepcopy(num_of_games_hist)\n",
    "\n",
    "for i in range(len(num_of_games_hist_data[0])):\n",
    "    num_of_games_hist_data[0][i] = int(round(num_of_games_hist_data[0][i], 0)) // 2\n",
    "\n",
    "histo_data = list(zip(*num_of_games_hist_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set title\n",
    "pd.DataFrame(\n",
    "    histo_data, \n",
    "    columns=['Number of Games Owned', 'frequency']\n",
    ").set_index(\n",
    "    'Number of Games Owned'\n",
    ").plot(kind='bar').title.set_text('Histogram for Number of Games Owned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the Computed Histogram into a Pandas Dataframe for plotting\n",
    "pd.DataFrame(\n",
    "    list(zip(*num_of_games_hist)), \n",
    "    columns=['bin', 'frequency']\n",
    ").set_index(\n",
    "    'bin'\n",
    ").plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_statistics_by_review_players(steam_reviews):\n",
    "    playerTypeData = steam_reviews.select(\"app_id\", \"app_name\", \"author_steamid\",\n",
    "                                            \"author_num_games_owned\", \"author_num_reviews\", \"author_playtime_forever\",\n",
    "                                            \"author_playtime_last_two_weeks\", \"author_playtime_at_review\", \"author_last_played\") \\\n",
    "                                    .where(col(\"author_steamid\").isNotNull() \\\n",
    "                                                    & col(\"author_num_games_owned\").isNotNull() \\\n",
    "                                                    & (col(\"author_num_reviews\").isNotNull()) \\\n",
    "                                                    & (col(\"author_playtime_forever\").isNotNull()) \\\n",
    "                                                    & (col(\"author_playtime_last_two_weeks\").isNotNull()) \\\n",
    "                                                    & (col(\"author_playtime_at_review\").isNotNull()) \\\n",
    "                                                    & (col(\"author_last_played\").isNotNull())  )\n",
    "    \n",
    "    gameName = playerTypeData.select(\"app_id\", \"app_name\").distinct()\n",
    "\n",
    "    playerType = playerTypeData.groupBy(col(\"app_id\")) \\\n",
    "                                .agg( \\\n",
    "                                    F.count(\"author_steamid\").alias(\"review_count\"), \\\n",
    "                                    F.avg(\"author_num_games_owned\").alias(\"avg_num_games_owned\"), \\\n",
    "                                    F.avg(\"author_num_reviews\").alias(\"avg_num_reviews\"), \\\n",
    "                                    F.avg(\"author_playtime_forever\").alias(\"avg_playtime_forever\"), \\\n",
    "                                    F.avg(\"author_playtime_last_two_weeks\").alias(\"avg_playtime_last_two_weeks\"), \\\n",
    "                                    F.avg(\"author_playtime_at_review\").alias(\"avg_playtime_at_review\"), \\\n",
    "                                    F.avg(\"author_last_played\").alias(\"avg_last_played\") \\\n",
    "                                )\n",
    "\n",
    "    playerType = gameName.join(playerType, \"app_id\").orderBy(col(\"app_id\").cast(types.IntegerType()))\n",
    "\n",
    "    return playerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------------+-------------------+------------------+--------------------+---------------------------+----------------------+--------------------+\n",
      "|app_id|            app_name|review_count|avg_num_games_owned|   avg_num_reviews|avg_playtime_forever|avg_playtime_last_two_weeks|avg_playtime_at_review|     avg_last_played|\n",
      "+------+--------------------+------------+-------------------+------------------+--------------------+---------------------------+----------------------+--------------------+\n",
      "|    70|           Half-Life|       44611| 141.27672547129632|18.642711438882788|  2603.1238259622064|         30.511533029970188|    1394.7682634327857|1.5558420368041964E9|\n",
      "|   240|Counter-Strike: S...|       99368| 101.36122292891072|11.720584091458015|  29419.339928347155|          85.13779083809678|    20401.543917558974| 1.544887758720876E9|\n",
      "|   420|Half-Life 2: Epis...|       17820| 190.68894500561169|29.941021324354658|   993.9797418630752|         11.930246913580246|     664.6397867564534|1.4927945586136925E9|\n",
      "|   620|            Portal 2|      183291| 130.81064536720297|12.634504694720418|  2300.4344184929973|          21.39173227272479|     1473.187827007327|1.5526016629318843E9|\n",
      "|  2870|           X Rebirth|        3595|  284.8698191933241|15.842837273991655|   7336.227816411683|         3.1944367176634216|     3967.242559109875| 1.475596180045619E9|\n",
      "|  4000|         Garry's Mod|      525596|   77.4815637866346| 7.845622873842267|   33628.88312506183|          185.7786531860973|    20217.305925083143|1.5798907791062033E9|\n",
      "|  7510|            X-Blades|        1779|  334.5435637998876|56.369870713884204|   556.3288364249578|         2.3147835862844293|     256.1877459246768|1.4910180300483418E9|\n",
      "|  8870|   BioShock Infinite|       74724| 204.72050479096407|15.542543225737381|   1512.653257320272|          7.382032546437557|    1023.0985091804507|1.5144250135902789E9|\n",
      "|  8930|Sid Meier's Civil...|      135331| 164.58824659538465|  9.72069961797371|  25755.899077077684|          88.44292881896979|    16047.794614685476|1.5555074492354302E9|\n",
      "| 32470|STAR WARS Empire...|       16526| 101.51863729880189| 10.14716204768244|  12214.898886602929|         203.91159385211182|     6922.159324700472| 1.592551761001089E9|\n",
      "| 35140|Batman: Arkham As...|       21724|  250.3533419259805| 24.03466212483889|   1439.284846252992|         13.646197753636532|     963.4286043085988| 1.502481045017124E9|\n",
      "| 39210|FINAL FANTASY XIV...|       22125| 193.32126553672316| 8.151005649717515|   92562.45306214689|          993.0058757062147|     51267.89948022599|1.5893256441462598E9|\n",
      "| 40800|      Super Meat Boy|       20637|  272.2860396375442|21.883510200125986|   1156.138682948103|          8.258467800552406|     772.4873285845811| 1.504364818514319E9|\n",
      "| 47890|      The Sims(TM) 3|       17536| 104.57059762773723|12.520187043795621|   14853.68818430657|          84.89672673357664|     7957.477075729927|1.5607895503430657E9|\n",
      "| 48700|Mount & Blade: Wa...|       96692| 135.82665577296984|10.689395192983907|  22082.131158730816|          89.83723575890457|    13277.018439995036|1.5759557232892897E9|\n",
      "| 55230|Saints Row: The T...|       44196| 207.36123178568195|19.899402660874287|   3266.175400488732|         13.072766766223188|    2116.0729930310436|1.5229292268027875E9|\n",
      "| 72850|The Elder Scrolls...|      225250|  167.9643374028857|10.307764705882352|  16060.131538290789|          30.84463041065483|    10481.863795782463|1.5391179803838935E9|\n",
      "|105600|            Terraria|      544948|  88.95804370325241| 6.758852220762348|  17439.060558071596|         119.21313776727321|    10663.213255209672| 1.593839637112385E9|\n",
      "|107410|              Arma 3|      142112|  112.6123972641297|  9.04634372888989|   47622.04979171358|         242.84435515649628|    26342.293887919386|1.5768036571105607E9|\n",
      "|113200|The Binding of Isaac|       37293| 250.64341833588074|  16.5440163033277|   4771.605797334621|          6.595232349234441|    3124.0889711205855| 1.497436543938219E9|\n",
      "+------+--------------------+------------+-------------------+------------------+--------------------+---------------------------+----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "playerType = get_game_statistics_by_review_players(steam_reviews)\n",
    "playerType.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/n488fsxn7ndc1kw3hf1k47000000gn/T/ipykernel_15995/327886810.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  playerType.toPandas().corr()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_count</th>\n",
       "      <th>avg_num_games_owned</th>\n",
       "      <th>avg_num_reviews</th>\n",
       "      <th>avg_playtime_forever</th>\n",
       "      <th>avg_playtime_last_two_weeks</th>\n",
       "      <th>avg_playtime_at_review</th>\n",
       "      <th>avg_last_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>review_count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.331225</td>\n",
       "      <td>-0.302816</td>\n",
       "      <td>0.383757</td>\n",
       "      <td>0.233205</td>\n",
       "      <td>0.397760</td>\n",
       "      <td>0.159008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_num_games_owned</th>\n",
       "      <td>-0.331225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826036</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.357249</td>\n",
       "      <td>-0.290290</td>\n",
       "      <td>-0.543356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_num_reviews</th>\n",
       "      <td>-0.302816</td>\n",
       "      <td>0.826036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.349989</td>\n",
       "      <td>-0.369261</td>\n",
       "      <td>-0.337647</td>\n",
       "      <td>-0.574040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_playtime_forever</th>\n",
       "      <td>0.383757</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.349989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728988</td>\n",
       "      <td>0.994507</td>\n",
       "      <td>0.232679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_playtime_last_two_weeks</th>\n",
       "      <td>0.233205</td>\n",
       "      <td>-0.357249</td>\n",
       "      <td>-0.369261</td>\n",
       "      <td>0.728988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703573</td>\n",
       "      <td>0.395946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_playtime_at_review</th>\n",
       "      <td>0.397760</td>\n",
       "      <td>-0.290290</td>\n",
       "      <td>-0.337647</td>\n",
       "      <td>0.994507</td>\n",
       "      <td>0.703573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_last_played</th>\n",
       "      <td>0.159008</td>\n",
       "      <td>-0.543356</td>\n",
       "      <td>-0.574040</td>\n",
       "      <td>0.232679</td>\n",
       "      <td>0.395946</td>\n",
       "      <td>0.213022</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review_count  avg_num_games_owned  \\\n",
       "review_count                     1.000000            -0.331225   \n",
       "avg_num_games_owned             -0.331225             1.000000   \n",
       "avg_num_reviews                 -0.302816             0.826036   \n",
       "avg_playtime_forever             0.383757            -0.306484   \n",
       "avg_playtime_last_two_weeks      0.233205            -0.357249   \n",
       "avg_playtime_at_review           0.397760            -0.290290   \n",
       "avg_last_played                  0.159008            -0.543356   \n",
       "\n",
       "                             avg_num_reviews  avg_playtime_forever  \\\n",
       "review_count                       -0.302816              0.383757   \n",
       "avg_num_games_owned                 0.826036             -0.306484   \n",
       "avg_num_reviews                     1.000000             -0.349989   \n",
       "avg_playtime_forever               -0.349989              1.000000   \n",
       "avg_playtime_last_two_weeks        -0.369261              0.728988   \n",
       "avg_playtime_at_review             -0.337647              0.994507   \n",
       "avg_last_played                    -0.574040              0.232679   \n",
       "\n",
       "                             avg_playtime_last_two_weeks  \\\n",
       "review_count                                    0.233205   \n",
       "avg_num_games_owned                            -0.357249   \n",
       "avg_num_reviews                                -0.369261   \n",
       "avg_playtime_forever                            0.728988   \n",
       "avg_playtime_last_two_weeks                     1.000000   \n",
       "avg_playtime_at_review                          0.703573   \n",
       "avg_last_played                                 0.395946   \n",
       "\n",
       "                             avg_playtime_at_review  avg_last_played  \n",
       "review_count                               0.397760         0.159008  \n",
       "avg_num_games_owned                       -0.290290        -0.543356  \n",
       "avg_num_reviews                           -0.337647        -0.574040  \n",
       "avg_playtime_forever                       0.994507         0.232679  \n",
       "avg_playtime_last_two_weeks                0.703573         0.395946  \n",
       "avg_playtime_at_review                     1.000000         0.213022  \n",
       "avg_last_played                            0.213022         1.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/02 23:22:44 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 3525373 ms exceeds timeout 120000 ms\n",
      "23/11/02 23:22:44 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/11/02 23:22:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:22:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:22:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:22:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:23:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:23:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/11/02 23:24:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/11/02 23:24:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:24:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:25:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:25:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:25:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/02 23:25:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:25:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:25:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:25:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:25:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:25:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:25:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:26:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:26:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:26:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:26:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:26:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:26:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:48:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:48:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:49:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:50:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:51:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:52:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/11/03 00:53:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/11/03 00:53:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:53:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:54:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@d142-058-168-148.wireless.sfu.ca:64624\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/11/03 00:55:59 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "playerType.toPandas().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_owned_vs_playtime_forever = playerType.select(\"app_name\", \"avg_playtime_at_review\", \"avg_playtime_forever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='avg_playtime_at_review', ylabel='avg_playtime_forever'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "games_owned_vs_playtime_forever.toPandas().plot.scatter(x='avg_playtime_at_review', y='avg_playtime_forever') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/n488fsxn7ndc1kw3hf1k47000000gn/T/ipykernel_15995/4281973665.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  games_owned_vs_playtime_forever.toPandas().corr()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_num_games_owned</th>\n",
       "      <th>avg_playtime_forever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_num_games_owned</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.37387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_playtime_forever</th>\n",
       "      <td>-0.37387</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      avg_num_games_owned  avg_playtime_forever\n",
       "avg_num_games_owned               1.00000              -0.37387\n",
       "avg_playtime_forever             -0.37387               1.00000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_owned_vs_playtime_forever.toPandas().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='avg_playtime_forever', ylabel='avg_num_games_owned'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "games_owned_vs_playtime_forever.toPandas().plot.scatter(x='avg_playtime_forever', y='avg_num_games_owned') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/n488fsxn7ndc1kw3hf1k47000000gn/T/ipykernel_15995/4281973665.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  games_owned_vs_playtime_forever.toPandas().corr()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_num_games_owned</th>\n",
       "      <th>avg_playtime_forever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_num_games_owned</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.306484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_playtime_forever</th>\n",
       "      <td>-0.306484</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      avg_num_games_owned  avg_playtime_forever\n",
       "avg_num_games_owned              1.000000             -0.306484\n",
       "avg_playtime_forever            -0.306484              1.000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_owned_vs_playtime_forever.toPandas().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
